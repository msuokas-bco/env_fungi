---
title: "Processing fungal nanopore sequences"
mainfont: Aptos
format: pdf
always_allow_html: true
editor: visual
---

```{r, include=F}

# Allows to use different font sizes inside code chunks
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize",
         paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)})

# Some global options
knitr::opts_chunk$set(warning = F, message = F)
knitr::opts_chunk$set(fig.align = 'center')
knitr::opts_chunk$set(warning = F)
silent_library <- function(pkg) {
  suppressPackageStartupMessages(library(pkg, character.only = T))
}
```

#### Preprocessing

The Nanopore basecaller lacks support for demultiplexing dual indexes located on both the 5’ and 3’ ends of reads. Additionally, ligated libraries may contain reads in either orientation. To address these, we use `Cutadapt` for demultiplexing and `SeqKit` for reverse-complementing reads in the reverse orientation. The sequences are then merged, and PCR primers are trimmed. A Python wrapper script, BCO_demux_tool has been created to automate these steps. End result is demultiplexed fastq.gz read files.

#### ITSxpress (standalone)

`Itsxpress` is used to trim ITS region. The code extracts full ITS region. Cutadapt is used to remove short sequences.

```{bash, eval = F}

#!/bin/bash
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate base

# Define the input and output directories
input_dir="/homedir04/msuokas/r_projects/env_fungi/raw"  
output_dir="/homedir04/msuokas/r_projects/env_fungi/xpress"

# Create output subdirectories if they don't exist
mkdir -p "$output_dir"

# Loop over each file in the input directory
for file in "$input_dir"/*
do
    # Get the base name of the file (without path and extension)
    base_name=$(basename "$file" .fastq.gz)
    # Process with all regions option
    itsxpress --single_end --fastq "$file" --threads 20 \
    --region ALL --outfile "$output_dir/${base_name}_full.fastq.gz"
    
    cutadapt -m 50 -o "$output_dir/${base_name}_full_trimmed.fastq.gz" \
    "$output_dir/all/${base_name}_all.fastq.gz"
done

echo "Processing complete! Check the output directory for results."
```

Itsxpress sometimes leaves fastq sequence headers without DNA sequence. Such files will cause error when using vsearch to dereplicate sequences. We use support script to fix problematic files.

```{bash, eval=F}
bash fix_fastq.sh /homedir04/msuokas/r_projects/env_fungi/xpress/

```

#### Load R libraries

```{r, size = "tiny"}
library(tidyverse)
library(kableExtra)
library(ggthemes)
library(dada2)
library(mia)
library(ggsci)
```

#### Process extracted ITS region sequences

Import reads to qiime2

```{bash, eval=F}
# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10
# Run command
qiime tools import --type 'SampleData[SequencesWithQuality]' \
--input-path xpress/manifest.csv --output-path qiime2/full_its.qza \
--input-format SingleEndFastqManifestPhred33
```

Dereplicate sequences

```{bash, eval=F}

# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10

# Dereplicate
qiime vsearch dereplicate-sequences \
--i-sequences qiime2/full_its.qza \
--o-dereplicated-table qiime2/derep_table.qza \
--o-dereplicated-sequences qiime2/derep_seqs.qza \
--verbose
```

Pick denovo otus at 97 % identity level using `vsearch` plugin

```{bash, eval=F}

# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10

# Pick otus
qiime vsearch cluster-features-de-novo \
--i-sequences qiime2/derep_seqs.qza \
--i-table qiime2/derep_table.qza \
--p-perc-identity 0.97 --p-strand plus \
--p-threads 20 --output-dir qiime2/denovo
```

Filter rare features

```{bash, eval=F}

# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10

# QIIME 2 command to filter rare features
qiime feature-table filter-features \
--i-table qiime2/denovo/clustered_table.qza \
--p-min-frequency 10 \
--o-filtered-table qiime2/denovo/f10_table.qza

qiime feature-table filter-seqs \
--i-data qiime2/denovo/clustered_sequences.qza \
--i-table qiime2/denovo/f10_table.qza \
--o-filtered-data qiime2/denovo/f10_sequences.qza
```

\newpage

Identify chimeric sequences

```{bash, eval=F}

# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10

# Detect chimeras
qiime vsearch uchime-denovo \
--i-sequences qiime2/denovo/f10_sequences.qza \
--i-table qiime2/denovo/f10_table.qza \
--o-chimeras qiime2/denovo/chimeras.qza \
--o-stats qiime2/denovo/uchime-stats.qza \
--o-nonchimeras qiime2/denovo/nonchimeras.qza
```

Filter chimeric features from the table

```{bash, eval=F}

# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10

# Keep nonchimeric features in the table
qiime feature-table filter-features \
--i-table qiime2/denovo/f10_table.qza \
--m-metadata-file qiime2/denovo/nonchimeras.qza \
--o-filtered-table qiime2/otu_table.qza

```

Filter chimeric sequences

```{bash, eval=F}

# Activate conda environment
export PATH="/homedir04/msuokas/miniconda3/bin:$PATH"
source activate qiime-2024.10

# Keep nonchimeric sequences
qiime feature-table filter-seqs \
--i-data qiime2/denovo/f10_sequences.qza \
--i-table qiime2/otu_table.qza \
--o-filtered-data qiime2/otu_sequences.qza
```

\newpage

Import feature table and metadata to TSE

```{r, size="tiny"}
# Import feature table and sort sample names alphabetically
tse <- importQIIME2(featureTableFile = "qiime2/otu_table.qza")
tse <- tse[, sort(colnames(tse))]

# Import metadata file and add data to colData
metadata <- data.frame(read_tsv("qiime2/meta.tsv",
show_col_types = F))
metadata <- column_to_rownames(metadata, "Sampleid")
colData(tse) <- DataFrame(metadata)

# Check dimensions
tse
```

Import sequences and rearrange them to correspond assay table

```{r, size="tiny"}
# Import squence file
ref_sequences <- importQZA("qiime2/otu_sequences.qza")
ref_ids <- names(ref_sequences)
tse_ids <- rownames(tse)
# Check if all rownames are present in the reference IDs
if (!all(tse_ids %in% ref_ids)) {
stop("Not all rownames from tse are present in the reference sequences.")
}
# Reorder `ref_sequences` to match the order of `tse` rownames
ref_sequences_ordered <- ref_sequences[match(tse_ids, ref_ids)]
all(names(ref_sequences_ordered) == rownames(tse))
# Included ordered sequences to data object
referenceSeq(tse) <- ref_sequences_ordered
```

Classify taxonomy. This step is computionally heavy.

```{r, size="tiny", eval=F}
# Unite reference file
unite <- "/homedir04/msuokas/reference/sh_general_release_dynamic_s_04.04.2024.fasta"
# Assign taxonomy using dada2 assignTaxonomy function
taxa <- assignTaxonomy(referenceSeq(tse),unite, minBoot=60, multithread=10)
# Save result to rds file
saveRDS(taxa, "qiime2/taxonomy.rds")
```

\newpage

Process and include taxonomic results

```{r, size="tiny"}
# Read results
taxa <- data.frame(readRDS("qiime2/taxonomy.rds"))
# Remove taxa prefixes from each column
taxa <- as.data.frame(lapply(taxa, function(x) sub("^[a-z]__","", x)))
#Add taxonomy to rowData
rownames(taxa) <- NULL
rowData(tse) <- DataFrame(taxa)
# Rename rows
rownames(tse) <- paste0("OTU_", seq_len(nrow(tse)))
```

Prune non-fungal taxa

```{r, size="tiny"}
# Non-fungal taxa
tse <- tse[rowData(tse)$Kingdom %in% "Fungi",]
# Final dimensions
tse
```

#### Write results to files

**RDS**

```{r, size="tiny"}
saveRDS(tse, "qiime2/tse.rds")
```

**Abundance table**

```{r, size="tiny"}
#FeatureID will be rowname
abd <- data.frame(FeatureID = rownames(tse),assays(tse)$counts)
#Write
write_tsv(abd, "results/feature_table.tsv")
```

**Taxonomy table**

```{r, size="tiny"}
#FeatureID will be rowname
taxt <- data.frame(FeatureID = rownames(tse), rowData(tse))
#Write
write_tsv(taxt, "results/taxonomy.tsv")
```

**Feature sequences**

```{r, size="tiny"}
# Write fasta file
writeXStringSet(referenceSeq(tse), "results/repseq.fasta",
append = F, compress = F,
format = "fasta")
```

\newpage

**Metadata file**

```{r, size="tiny"}
metadf <- data.frame(colData(tse)) %>% rownames_to_column(var="Sampleid")
#write
write_tsv(metadf, "results/metadata.tsv")
```

#### Summary table

```{r, size="tiny"}
# Create data frame with counts information
summary_df <- data.frame(Samples = colData(tse)$Labc,
                         Reads = colSums(assay(tse, "counts")))
rownames(summary_df) <- NULL
kable(summary_df, caption = "ITS sequence summary") %>%
kable_styling(latex_options = c("HOLD_position", "striped", "scale_down"),
font_size = 11) %>% row_spec(0, background = "teal",
color = "white")
```

\newpage

#### Sequence length distribution

```{r, size="tiny", fig.dim=c(6.5,5)}

# Get sequences
seqset <- referenceSeq(tse) 

# Calculate sequence lengths
sequence_lengths <- nchar(seqset)

# Combine lengths into a single data frame in long format
its_df <- data.frame(
  Length = sequence_lengths,
  Region = factor(rep("ITSf", length(sequence_lengths))))

# Plot the density distribution
ggplot(its_df, aes(x = Length, fill = Region)) +
  geom_density(aes(y = ..count..), alpha = 1) +
  labs(title = "Sequence Length Distribution",
       x = "Sequence Length (nt)", y = "Count") +
  theme_hc() +
  scale_fill_lancet()
```
